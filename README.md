# kaggle 点击率预测

## 点击率预估
CTR 预估无论是在学术界还是在工业界都是一个很热的话题，尤其是在互联网的计算广告领域。在计算广告领域，CTR 的预估准确与否直接影响商业利润，所以各大公司都很重视 CTR 预估方面的工作。像在 BAT 这样的大平台，数据量巨大，不仅要考虑模型的精度，还要考虑模型训练的时间代价。线性模型更新快，非线性模型训练代价高。线性模型需要大量的特征工程，尤其是要做大量 cross-feature 来达到非线性效果。非线性模型模型本身具备拟合非线性的特点，所以相对于线性模型，做的特征工程会少很多。

## Data fields
- id: ad identifier
- click: 0/1 for non-click/click
- hour: format is YYMMDDHH, so 14091123 means 23:00 on Sept. 11, 2014 UTC.
- C1 -- anonymized categorical variable
- banner_pos
- site_id
- site_domain
- site_category
- app_id
- app_domain
- app_category
- device_id
- device_ip
- device_model
- device_type
- device_conn_type
- C14-C21 -- anonymized categorical variables

## 进度

### 执行 ./data/analyse.ipynb

对数据进行简要的分析，发现所有特征都是非连续型特征，并且存在样本不均衡的问题。
删掉了 id 列和日期列，生成 `./data/train_drop_id_hour.csv` 和 `./data/test_drop_id_hour.csv` 两个文件。

### 执行 my_preprocess.py

生成FFM、LightGBM 和 NN 的输入

生成以下文件：
- ./data/train_ffm.txt
- ./dta/valid_ffm.txt
- ./data/test_ffm.txt

- ./data/train_lgb.txt
- ./data/valid_lgb.txt
- ./data/test_lgb.txt

- ./data/train.txt
- ./data/valid.txt
- ./data/test.txt

head 10 train.txt
```
1,9,18,1540,2843,2862,4074,4161,4186,4670,24287,27305,27311,27333,29085,29094,29104,29509,29514,29578,29737,0
1,9,18,1540,2843,2862,4074,4161,4186,4655,24043,27305,27310,27329,29085,29094,29104,29509,29514,29579,29737,0
1,9,18,1540,2843,2862,4074,4161,4186,4655,24076,27305,27310,27333,29085,29094,29104,29509,29514,29579,29737,0
1,10,177,1670,2853,2862,4074,4161,4186,4655,24055,27305,27310,27553,29085,29094,29218,29509,29514,29578,29741,0
1,9,37,1560,2842,2862,4074,4161,4186,4655,24032,27305,27310,27345,29085,29094,29141,29509,29529,29582,29750,0
1,9,422,1849,2842,2862,4074,4161,4186,5725,24036,27305,27310,27382,29085,29094,29121,29509,29515,29578,29741,0
1,9,18,1540,2843,2862,4074,4161,4186,4655,24058,27305,27311,27330,29085,29094,29104,29509,29514,29578,29737,1
1,10,19,1541,2842,2862,4074,4161,4186,4655,24148,27305,27310,27406,29085,29094,29192,29511,29515,29631,29743,0
1,9,18,1540,2843,2862,4074,4161,4186,11581,24033,27305,27310,27326,29085,29094,29104,29509,29514,29578,29737,0
1,9,56,1577,2842,2862,4074,4161,4186,4655,24982,27305,27311,27551,29085,29094,29218,29509,29514,29580,29741,0
```

head 10 train_ffm.txt
```
0       0:1:1   1:9:1   2:18:1  3:1540:1        4:2843:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4670:1        10:24287:1      11:27305:1      12:27311:1      13:27333:1 14:29085:1      15:29094:1      16:29104:1      17:29509:1      18:29514:1      19:29578:1      20:29737:1
0       0:1:1   1:9:1   2:18:1  3:1540:1        4:2843:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24043:1      11:27305:1      12:27310:1      13:27329:1 14:29085:1      15:29094:1      16:29104:1      17:29509:1      18:29514:1      19:29579:1      20:29737:1
0       0:1:1   1:9:1   2:18:1  3:1540:1        4:2843:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24076:1      11:27305:1      12:27310:1      13:27333:1 14:29085:1      15:29094:1      16:29104:1      17:29509:1      18:29514:1      19:29579:1      20:29737:1
0       0:1:1   1:10:1  2:177:1 3:1670:1        4:2853:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24055:1      11:27305:1      12:27310:1      13:27553:1 14:29085:1      15:29094:1      16:29218:1      17:29509:1      18:29514:1      19:29578:1      20:29741:1
0       0:1:1   1:9:1   2:37:1  3:1560:1        4:2842:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24032:1      11:27305:1      12:27310:1      13:27345:1 14:29085:1      15:29094:1      16:29141:1      17:29509:1      18:29529:1      19:29582:1      20:29750:1
0       0:1:1   1:9:1   2:422:1 3:1849:1        4:2842:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:5725:1        10:24036:1      11:27305:1      12:27310:1      13:27382:1 14:29085:1      15:29094:1      16:29121:1      17:29509:1      18:29515:1      19:29578:1      20:29741:1
1       0:1:1   1:9:1   2:18:1  3:1540:1        4:2843:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24058:1      11:27305:1      12:27311:1      13:27330:1 14:29085:1      15:29094:1      16:29104:1      17:29509:1      18:29514:1      19:29578:1      20:29737:1
0       0:1:1   1:10:1  2:19:1  3:1541:1        4:2842:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24148:1      11:27305:1      12:27310:1      13:27406:1 14:29085:1      15:29094:1      16:29192:1      17:29511:1      18:29515:1      19:29631:1      20:29743:1
0       0:1:1   1:9:1   2:18:1  3:1540:1        4:2843:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:11581:1       10:24033:1      11:27305:1      12:27310:1      13:27326:1 14:29085:1      15:29094:1      16:29104:1      17:29509:1      18:29514:1      19:29578:1      20:29737:1
0       0:1:1   1:9:1   2:56:1  3:1577:1        4:2842:1        5:2862:1        6:4074:1        7:4161:1        8:4186:1        9:4655:1        10:24982:1      11:27305:1      12:27311:1      13:27551:1 14:29085:1      15:29094:1      16:29218:1      17:29509:1      18:29514:1      19:29580:1      20:29741:1
```

head 10 train_lgb.txt
```
 1       1       2       2       3       1       1       1       1       15      256     1       2       19      1       1       1       1       1       1       3
0       1       1       2       2       3       1       1       1       1       0       12      1       1       15      1       1       1       1       1       2       3
0       1       1       2       2       3       1       1       1       1       0       45      1       1       19      1       1       1       1       1       2       3
0       1       2       161     132     13      1       1       1       1       0       24      1       1       239     1       1       115     1       1       1       7
0       1       1       21      22      2       1       1       1       1       0       1       1       1       31      1       1       38      1       16      5       16
0       1       1       406     311     2       1       1       1       1       1070    5       1       1       68      1       1       18      1       2       1       7
1       1       1       2       2       3       1       1       1       1       0       27      1       2       16      1       1       1       1       1       1       3
0       1       2       3       3       2       1       1       1       1       0       117     1       1       92      1       1       89      3       2       54      9
0       1       1       2       2       3       1       1       1       1       6926    2       1       1       12      1       1       1       1       1       1       3
0       1       1       40      39      2       1       1       1       1       0       951     1       2       237     1       1       115     1       1       3       7
```


### 训练 FFM 模型

python train_ffm.py
```

// 先得到 train_ffm.txt.bin 和 valid_ffm.txt.bin

// 输出
['First check if the text file has already been converted to binary format (6.1 seconds)\n', 
'Binary file found. Skip converting text to binary\n', 
'First check if the text file has already been converted to binary format (0.7 seconds)\n', 
'Binary file found. Skip converting text to binary\n', 
'iter   tr_logloss   va_logloss      tr_time\n', 
'   1      0.39272      0.39254        164.1\n', 
'   2      0.38925      0.39089        328.0\n', 
'   3      0.38817      0.39020        492.2\n', 
'   4      0.38743      0.38916        659.4\n', 
'   5      0.38690      0.39146\n', 
'Auto-stop. Use model at 4th iteration.\n']

// 得到以下模型
./model/model_ffm
```

### 得到 FFM 层的输出

python get_ffm_output.py
```
// 得到以下三个文件
model_ffm tr_ffm.out
model_ffm va_ffm.out
model_ffm te_ffm.out
```

### 训练 GBDT 模型

python train_gbdt.py

```
// 参数设置可以参考
https://lightgbm.readthedocs.io/en/latest/Parameters.html

// 输出
[1]     valid_0's binary_logloss: 0.178659      valid_0's l2: 0.0267679
Training until validation scores don't improve for 5 rounds.
[2]     valid_0's binary_logloss: 0.171671      valid_0's l2: 0.024883
[3]     valid_0's binary_logloss: 0.16506       valid_0's l2: 0.0231519
[4]     valid_0's binary_logloss: 0.158839      valid_0's l2: 0.0215696
[5]     valid_0's binary_logloss: 0.152932      valid_0's l2: 0.0201107
[6]     valid_0's binary_logloss: 0.148027      valid_0's l2: 0.0189316
[7]     valid_0's binary_logloss: 0.144896      valid_0's l2: 0.0181947
[8]     valid_0's binary_logloss: 0.140688      valid_0's l2: 0.0172239
[9]     valid_0's binary_logloss: 0.142452      valid_0's l2: 0.017628
[10]    valid_0's binary_logloss: 0.140683      valid_0's l2: 0.0172228
[11]    valid_0's binary_logloss: 0.136733      valid_0's l2: 0.0163321
[12]    valid_0's binary_logloss: 0.136334      valid_0's l2: 0.0162432
[13]    valid_0's binary_logloss: 0.132578      valid_0's l2: 0.015417
[14]    valid_0's binary_logloss: 0.129153      valid_0's l2: 0.0146799
[15]    valid_0's binary_logloss: 0.126088      valid_0's l2: 0.0140333
[16]    valid_0's binary_logloss: 0.123293      valid_0's l2: 0.0134549
[17]    valid_0's binary_logloss: 0.119885      valid_0's l2: 0.012764
[18]    valid_0's binary_logloss: 0.122 valid_0's l2: 0.0131909
[19]    valid_0's binary_logloss: 0.118505      valid_0's l2: 0.0124886
[20]    valid_0's binary_logloss: 0.115412      valid_0's l2: 0.0118813
[21]    valid_0's binary_logloss: 0.116001      valid_0's l2: 0.011996
[22]    valid_0's binary_logloss: 0.116536      valid_0's l2: 0.0121004
[23]    valid_0's binary_logloss: 0.115474      valid_0's l2: 0.0118933
[24]    valid_0's binary_logloss: 0.117339      valid_0's l2: 0.0122582
[25]    valid_0's binary_logloss: 0.11414       valid_0's l2: 0.0116353
[26]    valid_0's binary_logloss: 0.111114      valid_0's l2: 0.0110593
[27]    valid_0's binary_logloss: 0.108256      valid_0's l2: 0.0105272
[28]    valid_0's binary_logloss: 0.108638      valid_0's l2: 0.0105976
[29]    valid_0's binary_logloss: 0.10877       valid_0's l2: 0.010622
[30]    valid_0's binary_logloss: 0.109975      valid_0's l2: 0.0108458
[31]    valid_0's binary_logloss: 0.110119      valid_0's l2: 0.0108727
[32]    valid_0's binary_logloss: 0.109698      valid_0's l2: 0.0107943
Early stopping, best iteration is:
[27]    valid_0's binary_logloss: 0.108256      valid_0's l2: 0.0105272
Save model...
Start predicting...
The rmse of prediction is: 0.10704415422374455

// 得到以下模型（两种方式存储）
./model/lgb_model
./model/lbg.json
```

### 查看特征重要程度

python gbdt_feature_importance.py
```

['site_id' '0.4141326095028006']
['C17' '0.20695501853660517']
['C21' '0.1902369680472407']
['app_id' '0.09006392759897965']
['site_domain' '0.06839034259920918']
['C14' '0.013581116322464228']
['app_domain' '0.010307471686985882']
['device_id' '0.006332545705714577']
['C1' '0.0']
['banner_pos' '0.0']
['site_category' '0.0']
['app_category' '0.0']
['device_ip' '0.0']
['device_model' '0.0']
['device_type' '0.0']
['device_conn_type' '0.0']
['C15' '0.0']
['C16' '0.0']
['C18' '0.0']
['C19' '0.0']
['C20' '0.0']
```

### 使用 eli5 分析参数
待续



